{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "P2_T2_Twitter_Feelings.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJ9QY5XsDM10"
      },
      "source": [
        "Importando librerias\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "As4pYK2yC2BM"
      },
      "source": [
        "import os\n",
        "import tweepy as twe\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zilg0C-gDRVC"
      },
      "source": [
        "Keys and access tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vjTThZgDWIb"
      },
      "source": [
        "consumer_key='rRDcXwmLS7LQCvomf9ajMPQAj'\n",
        "consumer_secret='guRSsPchvVDVuMVDD1bKtfjhZ9TyszwUeayrh0X8v54Y0yUI8J'\n",
        "access_token='1388558403690287109-bmeW4twot28AEnLcz1JjB9VfYYfr7P'\n",
        "access_token_secret='4k22yM1JL66fkWMkEtP0t5Per54BEZVq4ZIPHtvof3qRL'\n",
        "\n",
        "auth = twe.OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token,access_token_secret)\n",
        "api = twe.API(auth, wait_on_rate_limit=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hzcN2ehZGZs"
      },
      "source": [
        "Publicar un Tweet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mr30q_UQZIoc",
        "outputId": "5caef5f8-31be-4829-ea77-4b21ef043bf1"
      },
      "source": [
        "api.update_status(\"#SoyUstaTunja, subiendo mi primer tweet desde Python\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Status(_api=<tweepy.api.API object at 0x7ff050cd7ad0>, _json={'created_at': 'Wed May 05 21:22:18 +0000 2021', 'id': 1390054269030567940, 'id_str': '1390054269030567940', 'text': '#SoyUstaTunja, subiendo mi primer tweet desde Python', 'truncated': False, 'entities': {'hashtags': [{'text': 'SoyUstaTunja', 'indices': [0, 13]}], 'symbols': [], 'user_mentions': [], 'urls': []}, 'source': '<a href=\"https://help.twitter.com/en/using-twitter/how-to-tweet#source-labels\" rel=\"nofollow\">Feelingscrapper</a>', 'in_reply_to_status_id': None, 'in_reply_to_status_id_str': None, 'in_reply_to_user_id': None, 'in_reply_to_user_id_str': None, 'in_reply_to_screen_name': None, 'user': {'id': 1388558403690287109, 'id_str': '1388558403690287109', 'name': 'Nicolas Carreño', 'screen_name': 'nicolascap26', 'location': '', 'description': '', 'url': None, 'entities': {'description': {'urls': []}}, 'protected': False, 'followers_count': 0, 'friends_count': 0, 'listed_count': 0, 'created_at': 'Sat May 01 18:18:31 +0000 2021', 'favourites_count': 0, 'utc_offset': None, 'time_zone': None, 'geo_enabled': False, 'verified': False, 'statuses_count': 1, 'lang': None, 'contributors_enabled': False, 'is_translator': False, 'is_translation_enabled': False, 'profile_background_color': 'F5F8FA', 'profile_background_image_url': None, 'profile_background_image_url_https': None, 'profile_background_tile': False, 'profile_image_url': 'http://abs.twimg.com/sticky/default_profile_images/default_profile_normal.png', 'profile_image_url_https': 'https://abs.twimg.com/sticky/default_profile_images/default_profile_normal.png', 'profile_link_color': '1DA1F2', 'profile_sidebar_border_color': 'C0DEED', 'profile_sidebar_fill_color': 'DDEEF6', 'profile_text_color': '333333', 'profile_use_background_image': True, 'has_extended_profile': True, 'default_profile': True, 'default_profile_image': True, 'following': False, 'follow_request_sent': False, 'notifications': False, 'translator_type': 'none', 'withheld_in_countries': []}, 'geo': None, 'coordinates': None, 'place': None, 'contributors': None, 'is_quote_status': False, 'retweet_count': 0, 'favorite_count': 0, 'favorited': False, 'retweeted': False, 'lang': 'fr'}, created_at=datetime.datetime(2021, 5, 5, 21, 22, 18), id=1390054269030567940, id_str='1390054269030567940', text='#SoyUstaTunja, subiendo mi primer tweet desde Python', truncated=False, entities={'hashtags': [{'text': 'SoyUstaTunja', 'indices': [0, 13]}], 'symbols': [], 'user_mentions': [], 'urls': []}, source='Feelingscrapper', source_url='https://help.twitter.com/en/using-twitter/how-to-tweet#source-labels', in_reply_to_status_id=None, in_reply_to_status_id_str=None, in_reply_to_user_id=None, in_reply_to_user_id_str=None, in_reply_to_screen_name=None, author=User(_api=<tweepy.api.API object at 0x7ff050cd7ad0>, _json={'id': 1388558403690287109, 'id_str': '1388558403690287109', 'name': 'Nicolas Carreño', 'screen_name': 'nicolascap26', 'location': '', 'description': '', 'url': None, 'entities': {'description': {'urls': []}}, 'protected': False, 'followers_count': 0, 'friends_count': 0, 'listed_count': 0, 'created_at': 'Sat May 01 18:18:31 +0000 2021', 'favourites_count': 0, 'utc_offset': None, 'time_zone': None, 'geo_enabled': False, 'verified': False, 'statuses_count': 1, 'lang': None, 'contributors_enabled': False, 'is_translator': False, 'is_translation_enabled': False, 'profile_background_color': 'F5F8FA', 'profile_background_image_url': None, 'profile_background_image_url_https': None, 'profile_background_tile': False, 'profile_image_url': 'http://abs.twimg.com/sticky/default_profile_images/default_profile_normal.png', 'profile_image_url_https': 'https://abs.twimg.com/sticky/default_profile_images/default_profile_normal.png', 'profile_link_color': '1DA1F2', 'profile_sidebar_border_color': 'C0DEED', 'profile_sidebar_fill_color': 'DDEEF6', 'profile_text_color': '333333', 'profile_use_background_image': True, 'has_extended_profile': True, 'default_profile': True, 'default_profile_image': True, 'following': False, 'follow_request_sent': False, 'notifications': False, 'translator_type': 'none', 'withheld_in_countries': []}, id=1388558403690287109, id_str='1388558403690287109', name='Nicolas Carreño', screen_name='nicolascap26', location='', description='', url=None, entities={'description': {'urls': []}}, protected=False, followers_count=0, friends_count=0, listed_count=0, created_at=datetime.datetime(2021, 5, 1, 18, 18, 31), favourites_count=0, utc_offset=None, time_zone=None, geo_enabled=False, verified=False, statuses_count=1, lang=None, contributors_enabled=False, is_translator=False, is_translation_enabled=False, profile_background_color='F5F8FA', profile_background_image_url=None, profile_background_image_url_https=None, profile_background_tile=False, profile_image_url='http://abs.twimg.com/sticky/default_profile_images/default_profile_normal.png', profile_image_url_https='https://abs.twimg.com/sticky/default_profile_images/default_profile_normal.png', profile_link_color='1DA1F2', profile_sidebar_border_color='C0DEED', profile_sidebar_fill_color='DDEEF6', profile_text_color='333333', profile_use_background_image=True, has_extended_profile=True, default_profile=True, default_profile_image=True, following=False, follow_request_sent=False, notifications=False, translator_type='none', withheld_in_countries=[]), user=User(_api=<tweepy.api.API object at 0x7ff050cd7ad0>, _json={'id': 1388558403690287109, 'id_str': '1388558403690287109', 'name': 'Nicolas Carreño', 'screen_name': 'nicolascap26', 'location': '', 'description': '', 'url': None, 'entities': {'description': {'urls': []}}, 'protected': False, 'followers_count': 0, 'friends_count': 0, 'listed_count': 0, 'created_at': 'Sat May 01 18:18:31 +0000 2021', 'favourites_count': 0, 'utc_offset': None, 'time_zone': None, 'geo_enabled': False, 'verified': False, 'statuses_count': 1, 'lang': None, 'contributors_enabled': False, 'is_translator': False, 'is_translation_enabled': False, 'profile_background_color': 'F5F8FA', 'profile_background_image_url': None, 'profile_background_image_url_https': None, 'profile_background_tile': False, 'profile_image_url': 'http://abs.twimg.com/sticky/default_profile_images/default_profile_normal.png', 'profile_image_url_https': 'https://abs.twimg.com/sticky/default_profile_images/default_profile_normal.png', 'profile_link_color': '1DA1F2', 'profile_sidebar_border_color': 'C0DEED', 'profile_sidebar_fill_color': 'DDEEF6', 'profile_text_color': '333333', 'profile_use_background_image': True, 'has_extended_profile': True, 'default_profile': True, 'default_profile_image': True, 'following': False, 'follow_request_sent': False, 'notifications': False, 'translator_type': 'none', 'withheld_in_countries': []}, id=1388558403690287109, id_str='1388558403690287109', name='Nicolas Carreño', screen_name='nicolascap26', location='', description='', url=None, entities={'description': {'urls': []}}, protected=False, followers_count=0, friends_count=0, listed_count=0, created_at=datetime.datetime(2021, 5, 1, 18, 18, 31), favourites_count=0, utc_offset=None, time_zone=None, geo_enabled=False, verified=False, statuses_count=1, lang=None, contributors_enabled=False, is_translator=False, is_translation_enabled=False, profile_background_color='F5F8FA', profile_background_image_url=None, profile_background_image_url_https=None, profile_background_tile=False, profile_image_url='http://abs.twimg.com/sticky/default_profile_images/default_profile_normal.png', profile_image_url_https='https://abs.twimg.com/sticky/default_profile_images/default_profile_normal.png', profile_link_color='1DA1F2', profile_sidebar_border_color='C0DEED', profile_sidebar_fill_color='DDEEF6', profile_text_color='333333', profile_use_background_image=True, has_extended_profile=True, default_profile=True, default_profile_image=True, following=False, follow_request_sent=False, notifications=False, translator_type='none', withheld_in_countries=[]), geo=None, coordinates=None, place=None, contributors=None, is_quote_status=False, retweet_count=0, favorite_count=0, favorited=False, retweeted=False, lang='fr')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYI2YzH8agDO"
      },
      "source": [
        "Obtener data de twitter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgFcLIdTap5C"
      },
      "source": [
        "search_words ='#AnonymousColombia'\n",
        "date_since = '2021-05-04'\n",
        "new_search = search_words+\" -filter:retweets\"\n",
        "tweets = twe.Cursor(api.search, q=new_search,lang='es',since=date_since).items(10000)\n",
        "#[tweet.text for tweet in tweets]"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8m2b_afPdly8"
      },
      "source": [
        "Cargamos el CSV del corpus de google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Oya7MItdqZu",
        "outputId": "f32184bf-edcf-4069-8c63-c68e17e2c434"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UY5zLMSlcquJ"
      },
      "source": [
        "Convertir los tweets en Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpQQUpyRcth9"
      },
      "source": [
        "data_frame = [[tweet.user.screen_name, tweet.user.location,tweet.text] for tweet in tweets]\n",
        "\n",
        "tw_dataframe = pd.DataFrame(data= data_frame , columns=[\"user\",\"location\",\"text\"])\n",
        "tw_dataframe\n",
        "#guardamos el dataframe en un CSV\n",
        "tw_dataframe.to_csv('/content/drive/MyDrive/Colab Notebooks/DataTwitter/anonymousco_tweets.csv', index=False, encoding='utf-8')"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "id": "eLd1AG0AeZxc",
        "outputId": "3c1879e3-9543-41af-e855-9fd6d84f421d"
      },
      "source": [
        "tw_dataframe.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>thecarechimbaa</td>\n",
              "      <td>Bogotá, D.C., Colombia</td>\n",
              "      <td>\" Somos Anónimos, somos legión, no perdonamls,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>abell46s</td>\n",
              "      <td></td>\n",
              "      <td>EN EL TWET SE SEÑALA ELLA MISMA .... QUE COSAS...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>dahianaosp</td>\n",
              "      <td></td>\n",
              "      <td>#AnonymousColombia  #RCNMentiroso Vendidos , c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>abell46s</td>\n",
              "      <td></td>\n",
              "      <td>#AnonymousColombia ALVARO URIBE VELEZ #UribeDi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>abell46s</td>\n",
              "      <td></td>\n",
              "      <td>@VickyDavilaH #AnonymousColombia ALVARO URIBE ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Andres19901015</td>\n",
              "      <td></td>\n",
              "      <td>#AnonymousColombia #Anonymous Tengo una idea, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>camarozulia</td>\n",
              "      <td>Anonymous</td>\n",
              "      <td>Hay que tener mucho cuidado los heridos que se...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>abell46s</td>\n",
              "      <td></td>\n",
              "      <td>#AnonymousColombia ALVARO URIBE VELEZ #UribeDi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>teo_cardona1</td>\n",
              "      <td>Cali, Colombia</td>\n",
              "      <td>Mientras Q'hubo pregunta:\\n¿DÓNDE ESTÁN?\\nCara...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>javierbaezap2</td>\n",
              "      <td></td>\n",
              "      <td>Yo, esperando que  #AnonymousColombia arme el ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             user  ...                                               text\n",
              "0  thecarechimbaa  ...  \" Somos Anónimos, somos legión, no perdonamls,...\n",
              "1        abell46s  ...  EN EL TWET SE SEÑALA ELLA MISMA .... QUE COSAS...\n",
              "2      dahianaosp  ...  #AnonymousColombia  #RCNMentiroso Vendidos , c...\n",
              "3        abell46s  ...  #AnonymousColombia ALVARO URIBE VELEZ #UribeDi...\n",
              "4        abell46s  ...  @VickyDavilaH #AnonymousColombia ALVARO URIBE ...\n",
              "5  Andres19901015  ...  #AnonymousColombia #Anonymous Tengo una idea, ...\n",
              "6     camarozulia  ...  Hay que tener mucho cuidado los heridos que se...\n",
              "7        abell46s  ...  #AnonymousColombia ALVARO URIBE VELEZ #UribeDi...\n",
              "8    teo_cardona1  ...  Mientras Q'hubo pregunta:\\n¿DÓNDE ESTÁN?\\nCara...\n",
              "9   javierbaezap2  ...  Yo, esperando que  #AnonymousColombia arme el ...\n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9UhEM2levNd"
      },
      "source": [
        "Obtener corpus: Convirtiendo de XML a CSV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EP5lMuXlezFV"
      },
      "source": [
        "#librerias necesarias\n",
        "import xml.etree.ElementTree as etree\n",
        "import csv\n",
        "from os import scandir\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZFgE7L2iVxV"
      },
      "source": [
        "Funcion para listar archivos de un directorio"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dbhrq51xiZMQ"
      },
      "source": [
        "import os\n",
        "#listado de archivos desde un path\n",
        "def files_of_path(path):\n",
        "  return[obj.name for obj in os.scandir(path) if obj.is_file()]\n",
        "\n",
        "files = files_of_path(\"/content/drive/MyDrive/Colab Notebooks/Corpus/tass_2017\")\n",
        "for file in files:\n",
        "  print(file)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_d2UbQlw-1Lq"
      },
      "source": [
        "Funcion para convertir lists a csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0lLnxKB-4To"
      },
      "source": [
        "def list_to_csv(data, filename):\n",
        "  with open(filename, 'w', encoding='utf-8') as csvfile:\n",
        "    writer = csv.writer(csvfile, delimiter=',', lineterminator='\\n', quoting=csv.QUOTE_NONNUMERIC)\n",
        "    writer.writerows(data)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6ysR6JH-6kQ"
      },
      "source": [
        "Funcion para cargar un csv a una lista"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GUzsq-7jr5P"
      },
      "source": [
        "def csv_to_lists(filename):\n",
        "  messages =[]\n",
        "  labels =[]\n",
        "  with open(filename,'r',encoding = 'utf-8') as csvfile:\n",
        "    reader = csv.reader(csvfile,delimiter=',')\n",
        "    for row in reader:\n",
        "      messages.append(row[1])\n",
        "      labels.append(row[2])\n",
        "  return messages, labels"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNJDk5-B_F1N"
      },
      "source": [
        "## Funciones para parsear xml en un dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cEQR5HU_L9V"
      },
      "source": [
        "Corpus de general tweeid | content | sentiments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeaC7lQB_Xuk"
      },
      "source": [
        "def general_tass_to_list(filename):\n",
        "  tree = etree.parse(filename)\n",
        "  root = tree.getroot()\n",
        "  data = []\n",
        "\n",
        "  for tweet in root:\n",
        "    tweetId = tweet.find('tweetid').text\n",
        "    content = tweet.find('content').text\n",
        "    polarityValue = tweet.find('sentiments/polarity/value').text\n",
        "    data.append([tweetId, content.replace('\\n',' '), polarityValue])\n",
        "  return data"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnYZCXwB_b6m"
      },
      "source": [
        "def general_tass_2017_to_list(filename,qrel=None):\n",
        "  tree = etree.parse(filename)\n",
        "  root = tree.getroot()\n",
        "  data = []\n",
        "\n",
        "  for tweet in root:\n",
        "    tweetId = tweet.find('tweetid').text\n",
        "    content = tweet.find('content').text\n",
        "    polarityValue = qrel[tweetId]\n",
        "    data.append([tweetId, content.replace('\\n',' '), polarityValue])\n",
        "\n",
        "  return data"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qj36lADV_fly"
      },
      "source": [
        "Corpus politics tweetid | content | sentiments/polarity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iovZiuyI_iPg"
      },
      "source": [
        "def politics_tass_to_list(filename):\n",
        "  tree = etree.parse(filename)\n",
        "  root = tree.getroot()\n",
        "  data = []\n",
        "\n",
        "  for tweet in root:\n",
        "    tweetId = tweet.find('tweetid').text\n",
        "    content = tweet.find('content').text\n",
        "    aux = next((e for e in tweet.findall('sentiments/polarity') if e.find('entity') == None), None)\n",
        "    if aux != None:\n",
        "      polarityValue = aux.find('value').text\n",
        "      data.append([tweetId, content.replace('\\n',' '), polarityValue])\n",
        "  return data"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIM6P757_mN9"
      },
      "source": [
        "corpus de internacional tweetid | content | sentiments/polarity/value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNFHNNLt_ppr"
      },
      "source": [
        "def intertass_tass_to_list(filename, qrel=None):\n",
        "  tree = etree.parse(filename)\n",
        "  root = tree.getroot()\n",
        "  data = []\n",
        "\n",
        "  for tweet in root:\n",
        "    tweetId = tweet.find('tweetid').text\n",
        "    content = tweet.find('content').text\n",
        "    polarityValue = tweet.find('sentiment/polarity/value').text\n",
        "    if polarityValue == None:\n",
        "      polarityValue = qrel[tweetId]\n",
        "      data.append([tweetId, content.replace('\\n',' '), polarityValue])\n",
        "  return data"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Weu9iaDu_t1K"
      },
      "source": [
        "Parsear corpus de Social-TV (not finished)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9k50Hf1_4Y1",
        "outputId": "d305abe0-c67c-463f-f3a1-d3551f5201ad"
      },
      "source": [
        "from lxml import etree\n",
        "doc = etree.parse('/content/drive/MyDrive/Colab Notebooks/Corpus/tass_2017/Social-TV/socialtv-tweets-test.xml')\n",
        "raiz=doc.getroot()\n",
        "#print (raiz.tag)\n",
        "#print (len(raiz))\n",
        "tweet=raiz[1]\n",
        "print (tweet.text)\n",
        "print (tweet.attrib)\n",
        "print (tweet[0].text)\n",
        "for attr,value in tweet.items():\n",
        "  print (attr,value)\n",
        "print (tweet.get(\"sentiment\"))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "El \n",
            "{'id': '456544890499760129'}\n",
            "Barça\n",
            "id 456544890499760129\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhbT-E3PASWE",
        "outputId": "2f5ae9f2-cea7-4a48-8a0b-0ad6ccf408a4"
      },
      "source": [
        "from xml.dom import minidom\n",
        "def social_tv_to_list(filename):\n",
        "  xmldoc = minidom.parse(filename)\n",
        "  tweetlist = xmldoc.getElementsByTagName('tweet')\n",
        "  print(len(tweetlist))\n",
        "  print(tweetlist[0].attributes['id'].value)\n",
        "  sentimentlist = xmldoc.getElementsByTagName('sentiment')\n",
        "  print(sentimentlist[0].attributes['aspect'].value)\n",
        "\n",
        "social_tv_to_list(\"/content/drive/MyDrive/Colab Notebooks/Corpus/tass_2017/Social-TV/socialtv-tweets-test.xml\")"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000\n",
            "456544890097131521\n",
            "Entrenador\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qhO-DO0BD-1"
      },
      "source": [
        "Funcion para unir los tweets corpus general test con sus sentimientos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2ys2ulABEut"
      },
      "source": [
        "#Listar los id tweets | sentiment :P (Positivo) - N (Negativo) - NEU (NEUtro) - NONE (sin sentimiento)\n",
        "def gold_standard_to_dict(filename):\n",
        "  with open(filename, 'r') as csvfile:\n",
        "    reader = csv.reader(csvfile, delimiter='\\t')\n",
        "    data = {rows[0]: rows[1] for rows in reader}\n",
        "\n",
        "  return data"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_m42bQRoBKoM"
      },
      "source": [
        "Función para separar el 100% del corpus entre: Train : 70% - Test: 30%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIkKeF68BMn5"
      },
      "source": [
        "def generate_train_test_subsets(data, size):\n",
        "  codes = [d[0] for d in data]\n",
        "  labels = [d[2] for d in data]\n",
        "  codes_train, codes_test, labels_train, labels_test = train_test_split(codes, labels, train_size=size)\n",
        "  train_data = [d for d in data if d[0] in codes_train]\n",
        "  test_data = [d for d in data if d[0] in codes_test]\n",
        "  return train_data, test_data"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqMxeTizEzRK"
      },
      "source": [
        "Ejecutar cada funcion de parseo del corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbrMNk48E2rY"
      },
      "source": [
        "data = []\n",
        "\n",
        "#Parceamos el internacional TASS\n",
        "#tomamos el corpus internacional (test) y generamos una lista del ID del tweet y el sentimiento para agregarlo a la data\n",
        "qrel = gold_standard_to_dict(\"/content/drive/MyDrive/Colab Notebooks/Corpus/tass_2017/InterTASS/InterTASS_Test_res.qrel\")\n",
        "#como el test del corpus internacional esta sin los sentimientos es necesario agregarlos : qrel\n",
        "data.extend(intertass_tass_to_list(\"/content/drive/MyDrive/Colab Notebooks/Corpus/tass_2017/InterTASS/InterTASS_Test.xml\", qrel))\n",
        "data.extend(intertass_tass_to_list(\"/content/drive/MyDrive/Colab Notebooks/Corpus/tass_2017/InterTASS/InterTASS_development.xml\"))\n",
        "data.extend(intertass_tass_to_list(\"/content/drive/MyDrive/Colab Notebooks/Corpus/tass_2017/InterTASS/InterTASS_Training.xml\"))\n",
        "#Parceamos el General\n",
        "#NO-data.extend(DatasetHelper.general_tass_to_list(\"../datasets/tass_2017/InterTASS/general-test-tagged-3l.xml\"))\n",
        "#NO-data.extend(DatasetHelper.general_tass_to_list(\"../datasets/tass_2017/InterTASS/general-train-tagged-3l.xml\"))\n",
        "qrel = gold_standard_to_dict(\"/content/drive/MyDrive/Colab Notebooks/Corpus/tass_2017/General Corpus of TASS/general-sentiment-3l.qrel\")\n",
        "data.extend(general_tass_2017_to_list(\"/content/drive/MyDrive/Colab Notebooks/Corpus/tass_2017/General Corpus of TASS/general-tweets-test.xml\", qrel))\n",
        "#Parceamos el STOMPOL (politica)\n",
        "#data.extend(politics_tass_to_list(\"/content/drive/MyDrive/Colab Notebooks/Corpus/tass_2014/politics-test-tagged.xml\"))\n",
        "#separamos la data en train = 70%  | test = 30#\n",
        "test, train  = generate_train_test_subsets(data, size=0.3)\n",
        "list_to_csv(data,\"/content/dataset_2017_full.csv\")\n",
        "list_to_csv(train, '/content/dataset_2017_train.csv')\n",
        "list_to_csv(test, '/content/dataset_2017_test.csv')"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3HeoS6HHpx-"
      },
      "source": [
        "## Pre-procesamiento del corpus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKp-IdeTHtnA"
      },
      "source": [
        "Cargar librerias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZvozCu6HvU3"
      },
      "source": [
        "import re                                #operaciones regulares para la búsqueda y manipulación de cadenas\n",
        "from nltk import TweetTokenizer          #libreria para tokenizar\n",
        "from nltk.stem import SnowballStemmer    #algoritmo para clasificación de palabras\n",
        "#variables para mejorar la escritura (opcional)\n",
        "NORMALIZE = 'normalize'\n",
        "REMOVE = 'remove'\n",
        "MENTION = 'twmention'\n",
        "HASHTAG = 'twhashtag'\n",
        "URL = 'twurl'\n",
        "LAUGH = 'twlaugh'\n",
        "\n",
        "#definir que el algoritmo de clasificación use el idioma español\n",
        "_stemmer = SnowballStemmer('spanish')\n",
        "\n",
        "#definir una variable para la funcion de tokenizar (opcional)\n",
        "_tokenizer = TweetTokenizer().tokenize\n",
        "\n",
        "#variable para definir si quiero normalizar: normalize o eliminar: remove los hashtags, menciones y urls en los tweets\n",
        "_twitter_features=\"normalize\"\n",
        "#variable para definir si se desea tener convertir o no a la raiz de la palabra.\n",
        "_stemming=False"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozBkcNF6H2Po"
      },
      "source": [
        "Funciones/metodos de preprocesamiento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJOPKHOLIFTp"
      },
      "source": [
        "Quitar tildes y palabras coloquiales"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TNUNRQbIBDR"
      },
      "source": [
        "#lista de conversión para quitar las tildes a las vocales.\n",
        "DIACRITICAL_VOWELS = [('á','a'), ('é','e'), ('í','i'), ('ó','o'), ('ú','u'), ('ü','u')]\n",
        "\n",
        "#lista para corregir algunas palabras coloquiales / jerga en español (obviamente faltan más)\n",
        "SLANG = [('d','de'), ('[qk]','que'), ('xo','pero'), ('xa', 'para'), ('[xp]q','porque'),('es[qk]', 'es que'),\n",
        "         ('fvr','favor'),('(xfa|xf|pf|plis|pls|porfa)', 'por favor'), ('dnd','donde'), ('tb', 'también'),\n",
        "         ('(tq|tk)', 'te quiero'), ('(tqm|tkm)', 'te quiero mucho'), ('x','por'), ('\\+','mas')]"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3beswMnLIKxi"
      },
      "source": [
        "Normalizacion de risa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBStIi_6INGc"
      },
      "source": [
        "#metodo para normalizar las risas\n",
        "def normalize_laughs(message):\n",
        "  message = re.sub(r'\\b(?=\\w*[j])[aeiouj]{4,}\\b', LAUGH, message, flags=re.IGNORECASE)\n",
        "  message = re.sub(r'\\b(?=\\w*[k])[aeiouk]{4,}\\b', LAUGH, message, flags=re.IGNORECASE)\n",
        "  message = re.sub(r'\\b(?=\\w*[h])[aeiouk]{4,}\\b', LAUGH, message, flags=re.IGNORECASE)\n",
        "  message = re.sub(r'\\b(juas+|lol)\\b', LAUGH, message, flags=re.IGNORECASE)\n",
        "  return message"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rn4ZemXZISPF",
        "outputId": "34c99594-89e0-45ed-ebc1-6f0f69ee697d"
      },
      "source": [
        "print (normalize_laughs(\"esto muyy feliz jajajajaja o no tan feliz jejejejeje o mejor me rio a como papa noel JOJOJO o como en mileniams LOL  kakaka\"))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "esto muyy feliz twlaugh o no tan feliz twlaugh o mejor me rio a como papa noel twlaugh o como en mileniams twlaugh  twlaugh\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_EPF4q-IiAM"
      },
      "source": [
        "Función/método para eliminar o normalizar menciones, hashtags y URL de un mensaje (tweet)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MH0U9Mm3Ii2W"
      },
      "source": [
        "def process_twitter_features(message, twitter_features):\n",
        "\n",
        "  message = re.sub(r'[\\.\\,]http','. http', message, flags=re.IGNORECASE)\n",
        "  message = re.sub(r'[\\.\\,]#', '. #', message)\n",
        "  message = re.sub(r'[\\.\\,]@', '. @', message)\n",
        "\n",
        "  if twitter_features == REMOVE:\n",
        "    # eliminar menciones, hashtags y URL\n",
        "    message = re.sub(r'((?<=\\s)|(?<=\\A))(@|#)\\S+', '', message)\n",
        "    message = re.sub(r'\\b(https?:\\S+)\\b', '', message, flags=re.IGNORECASE)\n",
        "  elif twitter_features == NORMALIZE:\n",
        "    # cuando sea necesario se normalizaran las menciones, hashtags y URL\n",
        "    message = re.sub(r'((?<=\\s)|(?<=\\A))@\\S+', MENTION, message)\n",
        "    message = re.sub(r'((?<=\\s)|(?<=\\A))#\\S+', HASHTAG, message)\n",
        "    message = re.sub(r'\\b(https?:\\S+)\\b', URL, message, flags=re.IGNORECASE)\n",
        "\n",
        "  return message"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WngyvlM5In1y",
        "outputId": "975b5f72-50e2-4243-d154-87e0bd0f1f69"
      },
      "source": [
        "print(process_twitter_features(\"Rosell, una noche. Adivina quien!! http://t.co/PPAwijRX, jajajAja dime si NO ES DÍVERTIDÓÓ\",\"normalize\"))"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Rosell, una noche. Adivina quien!! twurl, jajajAja dime si NO ES DÍVERTIDÓÓ\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ot-Td0GGIu1y"
      },
      "source": [
        "Función/método general para el preprocesamiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93YiOuG9Iw3R"
      },
      "source": [
        "def preprocess(message):\n",
        "  # convertir a minusculas\n",
        "  message = message.lower()\n",
        "        \n",
        "  # eliminar números, retorno de linea y el tan odios retweet (de los viejos estilos de twitter)\n",
        "  message = re.sub(r'(\\d+|\\n|\\brt\\b)', '', message)\n",
        "        \n",
        "  # elimar vocales con signos diacríticos (posible ambigüedad)\n",
        "  for s,t in DIACRITICAL_VOWELS:\n",
        "    message = re.sub(r'{0}'.format(s), t, message)\n",
        "        \n",
        "  # eliminar caracteres repetidos \n",
        "  message = re.sub(r'(.)\\1{2,}', r'\\1\\1', message)\n",
        "       \n",
        "  # normalizar las risas\n",
        "  message = normalize_laughs(message)\n",
        "        \n",
        "  # traducir la jerga y terminos coloquiales sobre todo en el español\n",
        "  for s,t in SLANG:\n",
        "    message = re.sub(r'\\b{0}\\b'.format(s), t, message)\n",
        "\n",
        "  #normalizar/eliminar hashtags, menciones y URL\n",
        "  message = process_twitter_features(message, _twitter_features)\n",
        "\n",
        "  #Convertir las palabras a su raiz ( Bonita, bonito) -> bonit \n",
        "  if _stemming:\n",
        "    message = ' '.join(_stemmer.stem(w) for w in _tokenizer(message))\n",
        "\n",
        "  return message"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7j-YMBKI0hP",
        "outputId": "1ad84570-6476-4089-fc4a-846171a2ed6b"
      },
      "source": [
        "print(preprocess(\"LOL!! muy graciosa esta paguina https://actualidadpanamericana.com :-) jajajaja muy buena\"))"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "twlaugh!! muy graciosa esta paguina twurl :-) twlaugh muy buena\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZR3KtQ4I77W"
      },
      "source": [
        "Descargamos las librerias de NLTK"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YdsfJ2nI-vx",
        "outputId": "cfd42967-a0a4-405e-a790-7b395c2d54ec"
      },
      "source": [
        "#Descargamos la libreria de stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fh73es6hJCsd"
      },
      "source": [
        "Cargar CSV del corpus de Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmedA_WRJHjx",
        "outputId": "b6e71b3e-585f-46fa-b763-a04029a4100c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2St-tHPWJKXZ"
      },
      "source": [
        "Aplicamos preprocesamiento al CSV y creamos un nuevo CSV limpio"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwGH1vZDJKwB"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/luisFernandoCastellanosG/Machine_learning/master/Analisis_sentimientos_Twitter/espanish/datasets/Corpus/dataset_2017_full.csv', encoding='utf-8')\n",
        "#asignamos nombres a las columnas del csv para facilitar la busqueda de información\n",
        "df.columns = ['tweetid', 'tweet','sentiment']\n",
        "#aplicamos el preprocesamiento a los tweets con steaming =false\n",
        "df['tweet'] = df['tweet'].apply(preprocess)\n",
        "#eliminamos la columna tweetid que no nos sirve para entrenar y si nos genera mas uso de memoria \n",
        "df = df.drop(columns=\"tweetid\")\n",
        "#Es mejor trabajar con valores enteros que con letras\n",
        "#por lo tanto reemplazaremos los sentimientos que estan como NONE->-1 | NEU -> 0 | P->1 | N->2\n",
        "df.loc[df['sentiment'] == 'NONE', 'sentiment'] = '-1'\n",
        "df.loc[df['sentiment'] == 'NEU', 'sentiment'] = '0'\n",
        "df.loc[df['sentiment'] == 'P', 'sentiment'] = '1'\n",
        "df.loc[df['sentiment'] == 'N', 'sentiment'] = '2'\n",
        "df[\"sentiment\"].unique()\n",
        "#guardamos el dataset en un nuvevo CSV para facilitar su posterior uso\n",
        "df.to_csv('/content/dataset_2017_full_clean.csv', index=False, encoding='utf-8')"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0iTxmeB7JUrI"
      },
      "source": [
        "## Entrenando el modelo de aprendizaje"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65sH_u_uJZKa"
      },
      "source": [
        "Funciones de tokenizar/extraer tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7dr2O3cJXru",
        "outputId": "35414ad9-8429-44d0-e2e1-da12dc6ef607"
      },
      "source": [
        "#p2.1: funcion tokenizar con esteroides --tokeniza y limpia--\n",
        "print(\"p2.1: funcion tokenizar con esteroides --tokeniza y limpia--\")\n",
        "def tokenizer(text):\n",
        "    text = re.sub('<[^>]*>', '', text)\n",
        "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text.lower())\n",
        "    text = re.sub('[\\W]+', ' ', text.lower()) +' '.join(emoticons).replace('-', '')\n",
        "    tokenized = [w for w in text.split() if w not in stop]\n",
        "    return tokenized\n",
        "#p2.2: funcion para extraer un documento del dataset  \n",
        "print(\"p2.2: funcion para extraer un documento del dataset  \")\n",
        "def stream_docs(path):\n",
        "    with open(path, 'r', encoding='utf-8') as csv:\n",
        "        next(csv)  # skip header\n",
        "        for line in csv:\n",
        "            text, label = line[:-3],  int(line[-2])\n",
        "            yield text, label\n",
        "#p2.3: funcion que tomara una secuencia de documentos y devolvera un número particular de documentos\n",
        "def get_minibatch(doc_stream, size):\n",
        "    docs, y = [], []\n",
        "    try:\n",
        "        for _ in range(size):\n",
        "            text, label = next(doc_stream)\n",
        "            docs.append(text)\n",
        "            y.append(label)\n",
        "    except StopIteration:\n",
        "        return None, None\n",
        "    return docs, y"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "p2.1: funcion tokenizar con esteroides --tokeniza y limpia--\n",
            "p2.2: funcion para extraer un documento del dataset  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFpQnBWcJkoj",
        "outputId": "50ee1d32-f263-4e70-c0f9-fa33407cdd49"
      },
      "source": [
        "next(stream_docs(path='/content/dataset_2017_full_clean.csv'))"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('twmention ya era hora de volver al csgo y dejares el padel bienvenida ', 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWt2JHamJo_7"
      },
      "source": [
        "### Entrenamos el modelo con regresion lineal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10o7pa6YJtNh",
        "outputId": "118a88e0-a1a3-48e6-fe4c-a2220c85cad2"
      },
      "source": [
        "path='/content/dataset_2017_full_clean.csv'\n",
        "#p2: definimos una versión liviana de CountVectorizer+TfidfVectorizer llamada HashingVectorizer\n",
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "vect = HashingVectorizer(decode_error='ignore', \n",
        "                         n_features=2**21,\n",
        "                         preprocessor=None, \n",
        "                         tokenizer=tokenizer)\n",
        "\n",
        "#definimos como algoritmo la regressión logistica en el decenso gradiante \n",
        "\n",
        "clf = SGDClassifier(loss='log', random_state=1, max_iter=1)\n",
        "doc_stream = stream_docs(path)\n",
        "#p3. entrenamos \n",
        "import re\n",
        "import numpy as np\n",
        "#import pyprind\n",
        "from nltk.corpus import stopwords\n",
        "stop = stopwords.words('spanish')\n",
        "#pbar = pyprind.ProgBar(50)\n",
        "#definimos las clases con las cuales vamos a entrenar\n",
        "classes = np.array([-1,0, 1,2])\n",
        "#hacemos 50 repeticiones\n",
        "for _ in range(50):\n",
        "  #tomaremos grupos de 500 tweets para entrenar\n",
        "    X_train, y_train = get_minibatch(doc_stream, size=1000)\n",
        "    if not X_train:\n",
        "        break\n",
        "    X_train = vect.transform(X_train)\n",
        "    clf.partial_fit(X_train, y_train, classes=classes)\n",
        "    #pbar.update()\n",
        "#probamos la eficiencia del modelo con 5000 tweets .\n",
        "X_test, y_test = get_minibatch(doc_stream, size=5000)\n",
        "X_test = vect.transform(X_test)\n",
        "print('Presición del modelo: %.3f' % clf.score(X_test, y_test))\n",
        "#recalibramos el modelo.\n",
        "clf = clf.partial_fit(X_test, y_test)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Presición del modelo: 0.806\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsTwRyrCJ_i7"
      },
      "source": [
        "Serializamos (congelamos) el modelo para usarlo fuera de google colaboratory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkJLSsicKCIo"
      },
      "source": [
        "import pickle\n",
        "import os\n",
        "#creo una carpeta en mi google drive para guardar los archivos serializados\n",
        "dest = os.path.join('/content/twitterclassifier', 'pkl_objects')\n",
        "if not os.path.exists(dest):\n",
        "    os.makedirs(dest)\n",
        "#convertimos el clasificador y el stopword en archivo/objectos pkl\n",
        "pickle.dump(stop, open(os.path.join(dest, 'stopwords.pkl'), 'wb'), protocol=4)   \n",
        "pickle.dump(clf, open(os.path.join(dest, 'classifier.pkl'), 'wb'), protocol=4)\n",
        "#Es importante recordar que deben verificar que los dos archivos esten en su drive"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89-Bkk3GKHiH"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/twitterclassifier')"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BX5GtbLpKPq1"
      },
      "source": [
        "Deserializar los estimadores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "2Cd3ZcWnKRQP",
        "outputId": "a4682d13-c3cc-40f9-f47d-62815576b3d4"
      },
      "source": [
        "import pickle\n",
        "import re\n",
        "import os\n",
        "from vectorizer import vect  # archivo vectorizer.py \n",
        "clf = pickle.load(open(os.path.join('/content/twitterclassifier/pkl_objects', 'classifier.pkl'), 'rb'))"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-82-de541f41b5c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mvectorizer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvect\u001b[0m  \u001b[0;31m# archivo vectorizer.py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/twitterclassifier/pkl_objects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'classifier.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'vectorizer'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syKOixyFKthN"
      },
      "source": [
        "Clasificar un texto"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aWGM0sKKvZY",
        "outputId": "5e27b4a8-3191-4087-8610-b1b3c04a6d7b"
      },
      "source": [
        "import numpy as np\n",
        "#NONE->-1 | NEU -> 0 | P->1 | N->2\n",
        "label = {-1:'Sin sentimiento', 0:'Neutro', 1:'Positivo',2: 'Negativo'}\n",
        "\n",
        "#example = ['Te odio más que a la muerte']\n",
        "example1 = 'Odio mi vida hasta morir'\n",
        "example = [example1]\n",
        "#convertimos el texto en un vector de palabras y extraemos sus caracteristicas https://scikit-learn.org/stable/modules/feature_extraction.html\n",
        "textConvert = vect.transform(example)  \n",
        "print('*Predicción: %s\\n*Probabilidad: %.2f%%'%(label[clf.predict(textConvert)[0]], np.max(clf.predict_proba(textConvert))*100))\n",
        "print('*Predicción: %s'%label[clf.predict(textConvert)[0]])\n",
        "print(np.max(clf.predict_proba(textConvert))*100)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*Predicción: Negativo\n",
            "*Probabilidad: 49.19%\n",
            "*Predicción: Negativo\n",
            "49.186713386923984\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2unCuCAHK9td"
      },
      "source": [
        "Recorrer los tweets descargados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JTfFXBU8LChV",
        "outputId": "d5688ba5-58a6-477e-9399-3cf42e212287"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/DataTwitter/anonymousco_tweets.csv', encoding='utf-8')\n",
        "#creamos una columna llamada Sentimient donde guardaremos la predicción\n",
        "df['sentiment'] =''\n",
        "#creamos una columna llamada Probability donde guardaremos la acertabilidad que dio el clasificador\n",
        "df['probability']=0\n",
        "#conversión de sentimientos (numeros a palabras)= NONE->-1 | NEU -> 0 | P->1 | N->2\n",
        "label = {-1:'Sin sentimiento', 0:'Neutro', 1:'Positivo',2: 'Negativo'}\n",
        "for rowid in range(len(df.index)):\n",
        "  text=df['text'][rowid]\n",
        "  textConvert = vect.transform([text]) \n",
        "  df['sentiment'][rowid]=label[clf.predict(textConvert)[0]]\n",
        "  df['probability'][rowid]=np.max(clf.predict_proba(textConvert))*100\n",
        "df.head(20)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  from ipykernel import kernelapp as app\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>probability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Karla_JoleyB</td>\n",
              "      <td>NaN</td>\n",
              "      <td>INCLUSO LA POLICÍA ESTA AMENAZANDO DE MUERTE A...</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SaraMon20785762</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Iván Duque pretender conservar con balas lo qu...</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SanguinoSneider</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#SOSCaliDDHH #5Mayo #AnonymousColombia Cali, C...</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>JuanF20110</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://t.co/LjPs8hVJuF\\n#SOSColombiaNosEstanM...</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Jasvi_2408</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Sólo espero que mis amigos que están en la mar...</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Magenta_co</td>\n",
              "      <td>NaN</td>\n",
              "      <td>@ChalecosAmarill SOS COLOMBIA 🇨🇴 #SOSColombiaD...</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>cronopio2</td>\n",
              "      <td>Bogota - Colombia</td>\n",
              "      <td>@AnonymousOpsco @AnonymousOpCOL\\n@YourAnonNews...</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>GinaMor09358266</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Ya es hora de manifestarse.\\n#AnonymousColombi...</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>davidsora182000</td>\n",
              "      <td>Tunja, Colombia</td>\n",
              "      <td>Están acosadas las mafias oligárquicas! Que si...</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>PicklerickSr</td>\n",
              "      <td>NaN</td>\n",
              "      <td>@PoliciaColombia #AnonymousColombia  \\nDe tant...</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Richi88876219</td>\n",
              "      <td>NaN</td>\n",
              "      <td>@AnonymusNews_ @PoliciaColombia Maldita rata d...</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>iamliwla</td>\n",
              "      <td>JustinBieber FollowMe 29•10•15</td>\n",
              "      <td>El pueblo colombiano esperando #AnonymousColom...</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Billy_Sheards2</td>\n",
              "      <td>BOGOTÁ</td>\n",
              "      <td>Medio cagado que nosotros en Colombia elijamos...</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>anonymous28M</td>\n",
              "      <td>NaN</td>\n",
              "      <td>HAGAMOS ESTO VIRAL POR FAVOR.\\n#NosEstanMantan...</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Jasvi_2408</td>\n",
              "      <td>NaN</td>\n",
              "      <td>EN COLOMBIA LA NOCHE ES SINÓNIMO DE PURGA \\nAN...</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>_Sofi016_</td>\n",
              "      <td>NaN</td>\n",
              "      <td>@PicklerickSr @Aiidan_45 Bueno hicimos los pos...</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Richi88876219</td>\n",
              "      <td>NaN</td>\n",
              "      <td>@AnonymusNews_ @PoliciaColombia @IvanDuque @Al...</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>ivannna9_ed</td>\n",
              "      <td>NaN</td>\n",
              "      <td>ANTES DE LAS 7 TODOS EN CASA\\nANTES DE LAS 7 T...</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>FranLagut</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Alguien sabe por qué la cerdita de Colombia no...</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Laura36154498</td>\n",
              "      <td>NaN</td>\n",
              "      <td>DIFUNDAMOS POR FAVOR #AnonymousColombia #Colom...</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>69</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               user                        location  ... sentiment probability\n",
              "0      Karla_JoleyB                             NaN  ...  Positivo          53\n",
              "1   SaraMon20785762                             NaN  ...  Positivo          64\n",
              "2   SanguinoSneider                             NaN  ...  Positivo          66\n",
              "3        JuanF20110                             NaN  ...  Positivo          68\n",
              "4        Jasvi_2408                             NaN  ...  Positivo          82\n",
              "5        Magenta_co                             NaN  ...  Positivo          66\n",
              "6         cronopio2               Bogota - Colombia  ...  Positivo          65\n",
              "7   GinaMor09358266                             NaN  ...  Positivo          64\n",
              "8   davidsora182000                 Tunja, Colombia  ...  Positivo          71\n",
              "9      PicklerickSr                             NaN  ...  Positivo          62\n",
              "10    Richi88876219                             NaN  ...  Positivo          61\n",
              "11         iamliwla  JustinBieber FollowMe 29•10•15  ...  Positivo          67\n",
              "12   Billy_Sheards2                          BOGOTÁ  ...  Positivo          60\n",
              "13     anonymous28M                             NaN  ...  Positivo          68\n",
              "14       Jasvi_2408                             NaN  ...  Positivo          71\n",
              "15        _Sofi016_                             NaN  ...  Positivo          74\n",
              "16    Richi88876219                             NaN  ...  Positivo          66\n",
              "17      ivannna9_ed                             NaN  ...  Positivo          69\n",
              "18        FranLagut                             NaN  ...  Positivo          71\n",
              "19    Laura36154498                             NaN  ...  Positivo          69\n",
              "\n",
              "[20 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8jUCJZmMndL"
      },
      "source": [
        "df.to_csv('/content/anonymous_data_sentiment.csv', index=False, encoding='utf-8')"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qq6iXyu6M67P"
      },
      "source": [
        "#segunda forma de ejecutar el analisis (metodos)\n",
        "def f_prediction(row):\n",
        "  text=row['text']\n",
        "  textConvert = vect.transform([text]) \n",
        "  return label[clf.predict(textConvert)[0]]\n",
        "\n",
        "def f_probability(row):\n",
        "  text=row['text']\n",
        "  textConvert = vect.transform([text]) \n",
        "  return np.max(clf.predict_proba(textConvert))*100\n",
        "\n",
        "df[\"sentiment\"] = df.apply(f_prediction, axis=1) # recorriendo columnas\n",
        "df[\"probability\"] = df.apply(f_probability, axis=1) # recorriendo columnas"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "BWWOpAPxNiWl",
        "outputId": "7b2aefff-9704-4191-c501-6483980ab3db"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "#sentimientos = df[\"sentiment\"].unique()\n",
        "df.groupby('sentiment')['location'].nunique().plot(kind='bar')\n",
        "print(df.groupby(['sentiment']).size())\n",
        "#df.groupby(['sentiment']).size().unstack().plot(kind='bar',stacked=True)\n",
        "plt.show()"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sentiment\n",
            "Negativo      90\n",
            "Positivo    2248\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QwfEfh1OxEx",
        "outputId": "15743ef5-de6f-4b4e-9934-d27eb5c6228a"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2338 entries, 0 to 2337\n",
            "Data columns (total 5 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   user         2338 non-null   object \n",
            " 1   location     1134 non-null   object \n",
            " 2   text         2338 non-null   object \n",
            " 3   sentiment    2338 non-null   object \n",
            " 4   probability  2338 non-null   float64\n",
            "dtypes: float64(1), object(4)\n",
            "memory usage: 91.5+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}